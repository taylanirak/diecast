8.1 Single Server Deployment (MVP)
Infrastructure Overview (hyphen based)
Hosting Environment
- Provider: Hetzner Dedicated Server
- Specifications: 8 vCPU, 32 GB RAM, 500 GB SSD
Deployment Orchestration
- Coolify running on internal port 8000
- Responsible for application lifecycle management
Traffic Entry Point
- Traefik reverse proxy
- Exposed ports: 80 and 443
- Handles SSL termination and routing
Application Services
- Web application running on port 3000 with 2 replicas
- Admin panel running on port 3002 with 1 replica
- API service running on port 3001 with 2 replicas
Data and Background Services
- PostgreSQL database running on port 5432
- Redis cache running on port 6379
- Elasticsearch search engine running on port 9200
- MinIO object storage running on port 9000
- Background worker services running with 2 replicas
- Monitoring stack including Prometheus and Grafana
Resource Allocation
- Web services: 1 GB RAM per replica (2 GB total)
- Admin service: 1 GB RAM
- API services: 2 GB RAM per replica (4 GB total)
- Worker services: 1 GB RAM per replica (2 GB total)
- PostgreSQL: 4 GB RAM
- Redis: 2 GB RAM
- Elasticsearch: 2 GB RAM
- MinIO: 1 GB RAM
- Monitoring stack: 2 GB RAM
- System overhead: 4 GB RAM
- Total estimated usage: approximately 26 GB out of 32 GB
Plain Text Explanation
The single server deployment model is designed for the MVP stage, prioritizing simplicity, cost efficiency,
and operational control. All platform components are hosted on a single dedicated server, with Coolify
managing deployments and service orchestration. Traefik serves as the unified entry point for all incoming
traffic, handling HTTPS termination and routing requests to internal services. Application services are
scaled selectively, with higher replica counts assigned to user-facing and API workloads, while
administrative and supporting services run with minimal replicas. Databases, caches, search engines,
storage, background workers, and monitoring tools are colocated within the same environment but remain
isolated through container networking. Resource allocation is carefully planned to remain within safe limits,
leaving headroom for traffic spikes and background processing. This architecture provides a robust
foundation for early-stage production usage while allowing a clear migration path to multi-server or
cloud-based deployments as the platform scales.